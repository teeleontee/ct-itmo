{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFd8sMt90CxH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import special_ortho_group as sp\n",
        "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "from matplotlib import ticker, cm\n",
        "import matplotlib.colors as mcolor\n",
        "from matplotlib.ticker import LogFormatter, LogLocator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1n27gSU4Ktqv"
      },
      "outputs": [],
      "source": [
        "def gradient_descent(gradient, start, learn_rate, iterations):\n",
        "    vec = start\n",
        "    for _ in range(iterations):\n",
        "        vec += -learn_rate * gradient(vec)\n",
        "    return vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCzme0cfdl3s"
      },
      "outputs": [],
      "source": [
        "gradient_descent(gradient=lambda v: np.array([2 * v[0], 4 * v[1]**3]),\n",
        "                       start=np.array([1.0, 1.0]),\n",
        "                       learn_rate=0.05,\n",
        "                       iterations=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HlalRJublyn"
      },
      "outputs": [],
      "source": [
        "def dichotomy(fn, a, b, err):\n",
        "\n",
        "    while True:\n",
        "      if b - a < err:\n",
        "        break\n",
        "      delta = (b - a) / 6\n",
        "      x1 = (a + b) / 2 - delta\n",
        "      x2 = (a + b) / 2 + delta\n",
        "      fx1, fx2 = fn(x1), fn(x2)\n",
        "      if fx1 > fx2:\n",
        "        a, b = x1, b\n",
        "      elif fx1 < fx2:\n",
        "        a, b = a, x2\n",
        "      else:\n",
        "        break\n",
        "    return b\n",
        "\n",
        "def gradient_descent_by_error(function, start, learn_rate, error, points):\n",
        "    def gradient(vector):\n",
        "        calculated_gradient = np.zeros(vector.size)\n",
        "        for coord in range(0, error.size):\n",
        "            coord_offset = np.zeros(vector.size)\n",
        "            coord_offset[coord] = error[coord]\n",
        "            calculated_gradient[coord] = (function(vector + coord_offset) - function(vector)) / error[coord]\n",
        "        return calculated_gradient\n",
        "    vec = start\n",
        "    oldvec = []\n",
        "    while True:\n",
        "        oldvec = vec.copy()\n",
        "        vec += -learn_rate * gradient(vec)\n",
        "        if (np.absolute(vec - oldvec) < error).all():\n",
        "            break\n",
        "        if(len(points) == 4000):\n",
        "            break\n",
        "        points.append(vec.copy())\n",
        "\n",
        "    return vec\n",
        "def gradient_descent_with_dichotomy_by_error(function, start, error, points):\n",
        "    def gradient(vector):\n",
        "        calculated_gradient = np.zeros(vector.size)\n",
        "        for coord in range(0, error.size):\n",
        "            coord_offset = np.zeros(vector.size)\n",
        "            coord_offset[coord] = error[coord]\n",
        "            calculated_gradient[coord] = (function(vector + coord_offset) - function(vector)) / error[coord]\n",
        "        return calculated_gradient\n",
        "    vec = start\n",
        "    while True :\n",
        "        learn_rate_func = lambda lmbd: function(vec - lmbd * gradient(vec))\n",
        "        learn_rate = dichotomy(learn_rate_func, 0, 0.5, 10**-5)\n",
        "        oldvec = vec.copy();\n",
        "        vec += -learn_rate * gradient(vec)\n",
        "        if (np.absolute(vec - oldvec) < error).all():\n",
        "            break\n",
        "        points.append(vec.copy())\n",
        "        if(len(points)== 4000):\n",
        "            break\n",
        "    return vec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent_wolfe(function, start, c1, c2, error, points):\n",
        "    def gradient(vector):\n",
        "        calculated_gradient = np.zeros(vector.size)\n",
        "        for coord in range(0, error.size):\n",
        "            coord_offset = np.zeros(vector.size)\n",
        "            coord_offset[coord] = error[coord]\n",
        "            calculated_gradient[coord] = (function(vector + coord_offset) - function(vector)) / error[coord]\n",
        "        return calculated_gradient\n",
        "    def calc_rate(vector):\n",
        "        def phi(a):\n",
        "            return function(vector - a * gradient(vector))                   \n",
        "        def derivative_phi(point):\n",
        "            return (phi(point + 10**-4) - phi(point)) / 10**-4\n",
        "        def zoom(lo, hi):\n",
        "            a = hi\n",
        "            alast_ = 10\n",
        "            while True:\n",
        "                alast_ = a\n",
        "                a = abs(hi - lo) / 2\n",
        "                if abs(a - alast_) <= 10**-4:\n",
        "                    break\n",
        "                ret = a;\n",
        "                if phi(a) > phi(0) + c1 * a * derivative_phi(0) or phi(a) >= phi(lo):\n",
        "                    hi = a\n",
        "                else:\n",
        "                    if abs(derivative_phi(a)) <= -c2 * derivative_phi(0):\n",
        "                        ret = a\n",
        "                        break\n",
        "                    if derivative_phi(a)*(hi - lo) >= 0:\n",
        "                        hi = lo\n",
        "                    lo = a\n",
        "            return ret\n",
        "                    \n",
        "        a0 = 0\n",
        "        amax = 2\n",
        "        alast = a0\n",
        "        a = (a0 + amax) / 2\n",
        "        res = a\n",
        "        i = 1\n",
        "        while True:\n",
        "            if (abs(a - alast) <= 10**-4):\n",
        "                break\n",
        "            if phi(a) > phi(0) + c1 * a * derivative_phi(0) or (phi(a) >= phi(alast) and i > 1):\n",
        "                res = zoom(alast, a)\n",
        "                break\n",
        "            i += 1;\n",
        "\n",
        "            if abs(derivative_phi(a)) <= -c2 * derivative_phi(0):\n",
        "                res = a\n",
        "                break\n",
        "            if derivative_phi(a) >= 0:\n",
        "                res = zoom(a, alast)\n",
        "                break\n",
        "            alast = a\n",
        "            a = (a + amax)/2\n",
        "        return res\n",
        "            \n",
        "    vec = start\n",
        "    while True:\n",
        "        learn_rate = calc_rate(vec.copy())\n",
        "        oldvec = vec.copy()\n",
        "        print(learn_rate)\n",
        "        vec += -learn_rate * gradient(vec)\n",
        "        if (np.absolute(vec - oldvec) < error).all():\n",
        "          break\n",
        "        points.append(vec.copy())"
      ],
      "metadata": {
        "id": "RSaHIvlTg8Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUbOevK7cYQI"
      },
      "outputs": [],
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (12,10)\n",
        "\n",
        "def draw(type,function,d,points,xlim,ylim,label):\n",
        "  t = np.linspace(-d,d, 5000)\n",
        "  X, Y = np.meshgrid(t, t)\n",
        "  if(type ==0):\n",
        "      print(\"For gradient with constant  \\n\")\n",
        "  elif(type==1):\n",
        "      print(\"For gradient with dihotomy  \\n\")\n",
        "  elif(type==1):\n",
        "      print(\"For gradient with wolf condition  \\n\")\n",
        "  print(len(points))\n",
        "  fig, ax = plt.subplots()\n",
        "  plt.xlim(xlim)\n",
        "  plt.ylim(ylim)\n",
        "  grad=ax.plot([i[0] for i in points], [i[1] for i in points], 'o-', color=\"orange\",label=label)\n",
        "  plt.legend(loc=\"upper right\")\n",
        "  sor= sorted([function([p[0], p[1]]) for p in points])\n",
        "  cs = ax.contourf(X, Y, function([X, Y]), levels=sor,   norm=mcolor.LogNorm(),cmap='RdBu')\n",
        "  cbar = fig.colorbar(cs,ticks = LogLocator(subs=range(5)))\n",
        "  plt.ylabel(\"y\")\n",
        "  plt.xlabel(\"x\")\n",
        "  plt.show()\n",
        "def draw_by_single(function,d, startpoint, xlim, ylim,\n",
        "                   include_wolf):\n",
        "  learn_rate=0.05\n",
        "  points = [startpoint]\n",
        "  err=np.array([10**-4, 10**-4])\n",
        "  gradient_descent_with_dichotomy_by_error(function=function,\n",
        "                                start=startpoint.copy(),\n",
        "                                error = err,\n",
        "                                points=points)\n",
        "  draw(1,function,d,points,xlim,ylim,\"Градиентный спуск с дихотомией\")\n",
        "  points_c = [startpoint]\n",
        "  gradient_descent_by_error(function=function,start=startpoint.copy(),\n",
        "                            learn_rate=learn_rate,error=err,points=points_c)\n",
        "  draw(0,function,d,points_c,xlim,ylim,f\"Градиентный спуск с постоянным шагом: {learn_rate}\")\n",
        "  if(include_wolf):\n",
        "      a1=10**-4\n",
        "      a2= 0.1 \n",
        "      points_d =[]\n",
        "      gradient_descent_wolfe(function, startpoint, a1, a2, err, points_d)\n",
        "      draw(0,function,d,points_d,xlim,ylim,f\"Градиентный спуск с условием Вольфа: с1 ={a1}, c2 = {a2}\")\n",
        "def draw_both(function,d, startpoint, xlim, ylim):\n",
        "  learn_rate=0.075\n",
        "  err=np.array([10**-4, 10**-4])\n",
        "  points = [startpoint]\n",
        "  points_c = [startpoint]\n",
        "  gradient_descent_with_dichotomy_by_error(function=function,\n",
        "                                start=startpoint.copy(),\n",
        "                                error = err,\n",
        "                                points=points)\n",
        "  gradient_descent_by_error(function=function,start=startpoint.copy(),\n",
        "                            learn_rate=learn_rate,error=err,points=points_c)\n",
        "  t = np.linspace(-d,d, 1000)\n",
        "  X, Y = np.meshgrid(t, t)\n",
        "  print(\"For gradient with dihotomy  \\n\")\n",
        "  print(len(points))\n",
        "  print(\"For gradient with constant \\n\")\n",
        "  print(len(points_c))\n",
        "  fig, ax = plt.subplots()\n",
        "  plt.xlim(xlim)\n",
        "  plt.ylim(ylim)\n",
        "  ax.plot([i[0] for i in points_c], [i[1] for i in points_c], 'o-',color=\"green\",label =f\"Градиентный спуск с постоянным шагом: {learn_rate}\")\n",
        "  ax.plot([i[0] for i in points], [i[1] for i in points], 'o-',color=\"orange\",label = f\"Градиентный спуск с дихотомией\")\n",
        "  ax.legend(loc=\"upper right\")\n",
        "  sor= sorted(list(set([function([p[0], p[1]]) for p in points_c] +[function([p[0], p[1]]) for p in points] )))\n",
        "  cs = ax.contourf(X, Y, function([X, Y]), levels=sor,   norm=mcolor.LogNorm(),cmap='RdBu')\n",
        "  cbar = fig.colorbar(cs,ticks =LogLocator(subs=range(8)))\n",
        "  plt.ylabel(\"y\")\n",
        "  plt.xlabel(\"x\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oITA4aE-excK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6smiebInFZy"
      },
      "outputs": [],
      "source": [
        "def g (vector):\n",
        "    x = vector[0] \n",
        "    y = vector[1]\n",
        "    return x**2 + y**2 \n",
        "draw_by_single(g,15, np.array([-2.5, 2.2]), [-4., 4.], [-4.,4.],False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXiUMsOKFGfn"
      },
      "outputs": [],
      "source": [
        "def f (vector):\n",
        "    x = vector[0] \n",
        "    y = vector[1]\n",
        "    return (x+2*y -7)**2 +(2*x+y-5)**2\n",
        "draw_both(f, 8, np.array([3., -2.5]),[-5.0, 5.0], [-5.0, 5.0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCJ1jtuPTy3A"
      },
      "outputs": [],
      "source": [
        "def q (vector):\n",
        "    # return -vector[0]**2 + vector[1]**2  + vector[1]\n",
        "    x = vector[0] \n",
        "    y = vector[1]\n",
        "    return 0.26*(x**2 + y**2) +0.48*x*y\n",
        "    # return x*y\n",
        "draw_both(q,2, np.array([-1., -0.5]), [-1.5, 2.], [-2.,2.])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oC6YdtsNs19"
      },
      "outputs": [],
      "source": [
        "def generate_quadratic_form(n,k):\n",
        "  coef = np.random.randint(2,10)\n",
        "  diagonal = np.diag(np.random.randint(k,k*coef,n))\n",
        "  diagonal[0][0] = coef\n",
        "  diagonal[1][1] = k*coef\n",
        "  R = sp.rvs(n) \n",
        "  return R @ diagonal @ np.linalg.inv(R) ;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "sWYg6_I-PTjQ"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "print(\"test\")\n",
        "indexes = [2] +[x for x in range(5,52,5)]\n",
        "def test_nk(n,k):\n",
        "    a=0\n",
        "    for t in range(100):\n",
        "        matrix = generate_quadratic_form(n,k);\n",
        "        def fun(v):\n",
        "            ans=0.0\n",
        "            for i in range(n):\n",
        "                for j in range(n):\n",
        "                    ans+=(matrix[i][j]* v[i]*v[j])\n",
        "            return ans \n",
        "        points = []\n",
        "        gradient_descent_with_dichotomy_by_error(function=fun,\n",
        "                                                    start=np.array([0.1 for _ in range(n)]),\n",
        "                                                    error = np.array([10**-6 for i in range(n)]),\n",
        "                                                     points=points)\n",
        "        a+=len(points)\n",
        "    a = a//100\n",
        "    print(a)\n",
        "    data.append(a)\n",
        "    a=0  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "exhsdDm9PTjQ"
      },
      "outputs": [],
      "source": [
        "for k in indexes:\n",
        "    test_nk(2,k)\n",
        "plt.plot(indexes,data)\n",
        "plt.ylabel(\"Количество итераций\")\n",
        "plt.xlabel(\"Число обусловенности\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pM5tVfZ0PTjQ"
      },
      "outputs": [],
      "source": [
        "dimensions = [2,5,10,50,100,200]\n",
        "data=[]\n",
        "for n in dimensions:\n",
        "    test_nk(n,5)\n",
        "plt.plot(dimensions,data)\n",
        "plt.ylabel(\"Количество итераций\")\n",
        "plt.xlabel(\"Размерность пространства\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "hPtxvYqzPTjR"
      },
      "outputs": [],
      "source": [
        "def r(vector):\n",
        "    x = vector[0] \n",
        "    y = vector[1]\n",
        "    return - x*y+ x**(2)+16 *y**(2)\n",
        "    # return x*y\n",
        "draw_by_single(r,15, np.array([-0.5, 1.0]), [-0.5, 0.6], [-0.5,0.6],True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIijl-vNPTjR"
      },
      "outputs": [],
      "source": [
        "def r_scaled(vector):\n",
        "    x = vector[0] \n",
        "    y = vector[1]\n",
        "    return - x*(y/4)+ x**(2)+16 *(y/4)**(2)\n",
        "    # return x*y\n",
        "draw_by_single(r_scaled,15, np.array([-0.5, 1.0]), [-0.5, 0.6], [-0.5,0.6],True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_st=[-2.0,-1.5,-1.0,-0.5, 0. ,0.5,1.0,1.5,2.0]\n",
        "y_st=[-2.0,-1.5,-1.0,-0.5, 0. ,0.5,1.0,1.5,2.0]\n",
        "def calc_iterations(function):\n",
        "  for i in x_st:\n",
        "        for j in y_st:\n",
        "            if i == 0. and j == 0.:\n",
        "              continue\n",
        "            points_d = []\n",
        "            gradient_descent_by_error(function=function,\n",
        "                                start=np.array([i, j]),\n",
        "                                learn_rate=0.05,\n",
        "                                error = np.array([10**-4, 10**-4]),\n",
        "                                points=points_d)\n",
        "            print(\"x: \"+ str(i) +\" y: \" + str(j) + \" iters: \" + str(len(points_d)))\n",
        "            # draw_by_single(func,15, np.array([i, j]), [-2, 2], [-2,2])\n",
        "  "
      ],
      "metadata": {
        "id": "OivNn1rFRuz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_iterations(r)"
      ],
      "metadata": {
        "id": "-kqnVjFbTTD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxKlphtaPTjR"
      },
      "outputs": [],
      "source": [
        "func = [f,g,r]\n",
        "x_st=[-2.0,-1.5,-1.0,-0.5, 0. ,0.5,1,1.5,2.0]\n",
        "y_st=[-2.0,-1.5,-1.0,-0.5, 0. ,0.5,1,1.5,2.0]\n",
        "def gen_start_point(func):\n",
        "    for i in x_st:\n",
        "        for j in y_st:\n",
        "            if i == 0. and j == 0.:\n",
        "              continue\n",
        "            print(\"x: \"+ str(i) +\" y: \" + str(j))\n",
        "            draw_by_single(func,15, np.array([i, j]), [-2, 2], [-2,2],False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfWGhhb3PTjS"
      },
      "outputs": [],
      "source": [
        "gen_start_point(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANKhCDhrPTjS"
      },
      "outputs": [],
      "source": [
        "gen_start_point(g)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "StTBnMqhhAB2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}